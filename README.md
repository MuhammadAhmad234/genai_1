# ğŸ¤– GenAI-1 â€” Learn Generative AI from Scratch

A **beginner-friendly** hands-on project to learn and grasp the fundamentals of **Generative AI** using [LangChain](https://www.langchain.com/) and popular LLM providers. Each folder is a self-contained learning module that progressively builds your understanding â€” from invoking your first LLM to building a fully functional chatbot.

---

## ğŸ“š What You'll Learn

| Module             | Key Concepts                                                               |
| ------------------ | -------------------------------------------------------------------------- |
| **LLMs**           | Invoking a large language model for the first time                         |
| **ChatModels**     | Using Chat Models with OpenAI, HuggingFace (cloud & local)                 |
| **EmbeddedModels** | Text embeddings, document embeddings & semantic similarity                 |
| **Prompts**        | Prompt Templates, saving/loading templates, Streamlit UI                   |
| **Chatbot**        | LangChain messaging, ChatPromptTemplate, MessagesPlaceholder & CLI chatbot |

---

## ğŸ—‚ï¸ Project Structure

```
genai_1/
â”œâ”€â”€ LLMS/
â”‚   â””â”€â”€ llm_demo.py                  # Basic LLM invocation with GPT-3.5-Turbo
â”œâ”€â”€ ChatModels/
â”‚   â”œâ”€â”€ openaiChatDemo.py            # Chat with OpenAI GPT-4
â”‚   â”œâ”€â”€ huggingfaceChatDemo.py       # Chat using HuggingFace cloud endpoint
â”‚   â””â”€â”€ chatModelLocal.py           # Chat using a local HuggingFace model
â”œâ”€â”€ EmbeddedModels/
â”‚   â”œâ”€â”€ embeddingOpenai.py           # Generate embeddings for a single query
â”‚   â”œâ”€â”€ embeddingOpenaiDoc.py        # Generate embeddings for multiple documents
â”‚   â””â”€â”€ embeddingDocSimilarity.py    # Document similarity search with cosine similarity
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ promptGenerator.py           # Create & save a reusable PromptTemplate
â”‚   â””â”€â”€ promptUi.py                  # Streamlit UI â€” Research Paper Summarizer
â”œâ”€â”€ chatbot/
â”‚   â”œâ”€â”€ messages.py                  # LangChain built-in messaging (System, Human, AI)
â”‚   â”œâ”€â”€ chatbot.py                   # Interactive CLI chatbot with chat history
â”‚   â”œâ”€â”€ chatPromptTemplate.py        # Using ChatPromptTemplate with system & human messages
â”‚   â”œâ”€â”€ messagePlaceholder.py        # MessagesPlaceholder for injecting chat history
â”‚   â””â”€â”€ chatHistory.txt              # Sample chat history for MessagesPlaceholder demo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ template.json                    # Saved prompt template (generated by promptGenerator.py)
â””â”€â”€ .env                             # API keys (not committed)
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- API keys for one or more providers (see [API Keys](#-api-keys) below)

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/<your-username>/genai_1.git
   cd genai_1
   ```

2. **Create & activate a virtual environment**

   ```bash
   python -m venv venv

   # Windows
   venv\Scripts\activate

   # macOS / Linux
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**

   Create a `.env` file in the project root and add your API keys:

   ```env
   OPENAI_API_KEY=your_openai_api_key
   HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_token
   ```

---

## ğŸ“– Module Walkthroughs

### 1. LLMs â€” Your First LLM Call

> **File:** `LLMS/llm_demo.py`

The simplest starting point â€” invoke OpenAI's `gpt-3.5-turbo` with a single prompt and print the response.

```bash
python LLMS/llm_demo.py
```

---

### 2. ChatModels â€” Exploring Different Providers

> **Files:** `ChatModels/`

Learn how to use **Chat Models** from multiple providers:

| File                     | What It Does                                         |
| ------------------------ | ---------------------------------------------------- |
| `openaiChatDemo.py`      | Chat with **OpenAI GPT-4**                           |
| `huggingfaceChatDemo.py` | Chat via **HuggingFace Inference API** (cloud)       |
| `chatModelLocal.py`      | Chat using a **local HuggingFace model** (TinyLlama) |

```bash
python ChatModels/openaiChatDemo.py
python ChatModels/huggingfaceChatDemo.py
python ChatModels/chatModelLocal.py
```

---

### 3. EmbeddedModels â€” Text Embeddings & Similarity

> **Files:** `EmbeddedModels/`

Understand how text gets converted into numerical vectors and how to find the most relevant document for a given query.

| File                        | What It Does                                               |
| --------------------------- | ---------------------------------------------------------- |
| `embeddingOpenai.py`        | Generate an embedding vector for a **single query**        |
| `embeddingOpenaiDoc.py`     | Generate embeddings for **multiple documents**             |
| `embeddingDocSimilarity.py` | Find the **most similar document** using cosine similarity |

```bash
python EmbeddedModels/embeddingOpenai.py
python EmbeddedModels/embeddingDocSimilarity.py
```

---

### 4. Prompts â€” Templates & Streamlit UI

> **Files:** `prompts/`

Learn how to create structured, reusable **Prompt Templates** and build a simple web interface:

- **`promptGenerator.py`** â€” Define a prompt template with input variables and save it as `template.json`
- **`promptUi.py`** â€” A **Streamlit** web app that loads the saved template and lets you summarize research papers interactively

```bash
# Generate the template
python prompts/promptGenerator.py

# Launch the Streamlit UI
streamlit run prompts/promptUi.py
```

---

### 5. Chatbot â€” Messaging, Templates & CLI Chatbot

> **Files:** `chatbot/`

Build a conversational AI chatbot that remembers context, and learn how LangChain handles messages:

- **`messages.py`** â€” Understand LangChain's built-in message types (`SystemMessage`, `HumanMessage`, `AIMessage`)
- **`chatbot.py`** â€” A fully interactive **CLI chatbot** that maintains chat history across turns
- **`chatPromptTemplate.py`** â€” Use `ChatPromptTemplate` with system & human message placeholders
- **`messagePlaceholder.py`** â€” Use `MessagesPlaceholder` to inject prior chat history from a file
- **`chatHistory.txt`** â€” Sample conversation data used by the placeholder demo

```bash
# Understand messaging
python chatbot/messages.py

# ChatPromptTemplate demo
python chatbot/chatPromptTemplate.py

# MessagesPlaceholder demo
python chatbot/messagePlaceholder.py

# Run the chatbot (type "exit" to quit)
python chatbot/chatbot.py
```

---

## ğŸ”‘ API Keys

| Provider    | Environment Variable       | Get Your Key                                                             |
| ----------- | -------------------------- | ------------------------------------------------------------------------ |
| OpenAI      | `OPENAI_API_KEY`           | [platform.openai.com](https://platform.openai.com/api-keys)              |
| HuggingFace | `HUGGINGFACEHUB_API_TOKEN` | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |

---

## ğŸ› ï¸ Tech Stack

- **[LangChain](https://www.langchain.com/)** â€” LLM application framework
- **[OpenAI](https://openai.com/)** â€” GPT-3.5 / GPT-4 models & embeddings
- **[HuggingFace](https://huggingface.co/)** â€” Open-source models (cloud & local)
- **[Streamlit](https://streamlit.io/)** â€” Rapid web UI prototyping
- **[scikit-learn](https://scikit-learn.org/)** â€” Cosine similarity calculations
- **[python-dotenv](https://pypi.org/project/python-dotenv/)** â€” Environment variable management

---

## ğŸ“ License

This project is open source and available for learning purposes.

---

> **â­ If this repo helped you learn something new, consider giving it a star!**
